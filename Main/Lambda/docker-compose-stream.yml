version: '3'
services:
  # 1. Zookeeper Service
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    networks:
      - stream-network
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 30s
      timeout: 10s
      retries: 3

  # 2. Kafka Service
  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CREATE_TOPICS: "smartphoneTopic:1:1"
    depends_on:
      zookeeper:
        condition: service_healthy
    networks:
      - stream-network

  # 3. Hadoop NameNode
  hadoop-namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-namenode
    ports:
      - "9870:9870"
      - "9000:9000"
    environment:
      - CLUSTER_NAME=test-cluster
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    networks:
      - stream-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9870"]
      interval: 30s
      timeout: 10s
      retries: 3

  # 4. Hadoop DataNode
  hadoop-datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-datanode
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    environment:
      - SERVICE_PRECONDITION=hadoop-namenode:9870
    depends_on:
      hadoop-namenode:
        condition: service_healthy
    networks:
      - stream-network

  # 5. YARN ResourceManager
  yarn-resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    container_name: yarn-resourcemanager
    ports:
      - "8088:8088"
    depends_on:
      - hadoop-namenode
    networks:
      - stream-network

  # 6. YARN NodeManager
  yarn-nodemanager:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    container_name: yarn-nodemanager
    depends_on:
      - yarn-resourcemanager
    networks:
      - stream-network

  # 7. HBase with Thrift
  hbase:
    image: dajobe/hbase
    container_name: hbase
    ports:
      - "16000:16000"
      - "16010:16010"
      - "16020:16020"
      - "16030:16030"
      - "9090:9090"
    environment:
      HBASE_CONF_hbase_zookeeper_quorum: zookeeper
      HBASE_CONF_hbase_zookeeper_property_clientPort: 2181
      HBASE_MANAGES_ZK: "false"
    volumes:
      - hbase_data:/data
    depends_on:
      zookeeper:
        condition: service_healthy
      hadoop-namenode:
        condition: service_healthy
    networks:
      - stream-network
    command: ["sh", "-c", "start-hbase.sh && hbase thrift start -p 9090 && tail -f /dev/null"]

  # 8. Python Stream Pipeline
  stream-pipeline:
    build:
      context: .
      dockerfile: Stream_layer/Dockerfile.stream
    container_name: stream-pipeline
    volumes:
      - ./Stream_layer:/app/Stream_layer
      - ./Stream_data:/app/Stream_data
      - ./ML_operations:/app/ML_operations
      - ./producer.py:/app/producer.py
    environment:
      - KAFKA_HOST=kafka
      - KAFKA_PORT=9092
      - HBASE_HOST=hbase
      - HBASE_PORT=9090
    depends_on:
      - kafka
      - hbase
    networks:
      - stream-network

  # 9. Flask Web App
  flask-webapp:
    build:
      context: .
      dockerfile: real_time_web_app_Flask/Dockerfile.flask
    container_name: flask-webapp
    ports:
      - "5000:5000"
    volumes:
      - ./real_time_web_app_Flask:/app
    environment:
      - FLASK_APP=app.py
      - FLASK_ENV=development
    depends_on:
      - stream-pipeline
    networks:
      - stream-network

networks:
  stream-network:
    driver: bridge

volumes:
  hadoop_namenode:
  hadoop_datanode:
  hbase_data: