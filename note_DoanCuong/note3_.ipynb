{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### **2. Batch Layer**\n",
    "\n",
    "```\n",
    "1. Start the Apache Airflow instance:\n",
    "docker-compose up -d\n",
    "Access the Apache Airflow web UI (localhost:8080) and run the DAG\n",
    "\n",
    "@docker-compose.yaml \n",
    "\n",
    "\n",
    "2. Start Apache Spark\n",
    "spark-shell\n",
    "\n",
    "3. Start Apache zookeeper\n",
    "zookeeper-server-start.bat C:/kafka_2.13_2.6.0/config/zookeeper.properties\n",
    "\n",
    "4. Start Kafka server\n",
    "kafka-server-start.bat C:/kafka_2.13_2.6.0/config/server.properties\n",
    "Run the kafka producer\n",
    "kafka-console-producer.bat --topic smartphoneTopic --bootstrap-server localhost:9092\n",
    "Run the kafka consumer\n",
    "kafka-console-consumer.bat --topic smartphoneTopic --from-beginning --bootstrap-server localhost:9092\n",
    "\n",
    "5. Run HDFS and yarn (start-all or start-dfs and start-yarn)\n",
    "start-all  \n",
    "\n",
    "======\n",
    "\n",
    "Viết thành @docker-compose-batch.yml \n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "1. Check: Airflow và Dags: \n",
    "- Lỗi đường dẫn nên mình đã sửa bằng cách đưa hàm batch_layer vào dags luôn. \n",
    "- Check = PORT: 8080\n",
    "2. Check: \n",
    "Apach Spark Master và Apach Spark Worker là gì ?? \n",
    "- Master: 7077 (bug), và 9090:8080  (ok)\n",
    "- Worker: ??? ko có port\n",
    "\n",
    "\"\"\"\n",
    "Apache Spark Master và Worker là hai thành phần chính trong kiến trúc phân tán của Apache Spark:\n",
    "\n",
    "1. **Spark Master (Node chủ)**:\n",
    "- Là trung tâm điều phối của cụm Spark\n",
    "- Nhiệm vụ chính:\n",
    "  - Phân phối công việc cho các Worker nodes\n",
    "  - Quản lý tài nguyên trong cụm\n",
    "  - Theo dõi trạng thái của các Worker\n",
    "  - Điều phối việc thực thi các task\n",
    "- Giống như \"người quản lý\" điều phối công việc\n",
    "\n",
    "2. **Spark Worker (Node công nhân)**:\n",
    "- Là các node thực thi công việc\n",
    "- Nhiệm vụ chính:\n",
    "  - Thực thi các task được Master giao\n",
    "  - Báo cáo trạng thái cho Master\n",
    "  - Quản lý tài nguyên cục bộ (CPU, RAM)\n",
    "- Giống như \"công nhân\" thực hiện công việc\n",
    "\n",
    "Ví dụ hoạt động:\n",
    "```\n",
    "1. Client gửi job đến Master\n",
    "2. Master phân tích job và chia thành các task\n",
    "3. Master phân phối tasks cho các Worker\n",
    "4. Workers thực thi tasks và gửi kết quả về\n",
    "5. Master tổng hợp kết quả và trả về Client\n",
    "```\n",
    "\n",
    "Trong docker-compose của bạn:\n",
    "```yaml\n",
    "spark-master:\n",
    "    environment:\n",
    "      - SPARK_MODE=master\n",
    "      - SPARK_WORKER_MEMORY=1G\n",
    "      - SPARK_WORKER_CORES=1\n",
    "\n",
    "spark-worker:\n",
    "    environment:\n",
    "      - SPARK_MODE=worker\n",
    "      - SPARK_MASTER_URL=spark://spark-master:7077\n",
    "      - SPARK_WORKER_MEMORY=1G\n",
    "```\n",
    "\n",
    "- Master được cấu hình với 1GB RAM và 1 core\n",
    "- Worker kết nối đến Master qua port 7077\n",
    "- Worker cũng được cấp 1GB RAM để xử lý task\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Ah, tôi hiểu vấn đề của bạn:\n",
    "\n",
    "1. **Port 7077**:\n",
    "- Port này là RPC port (Remote Procedure Call) dùng cho giao tiếp nội bộ giữa Master và Worker\n",
    "- Không phải là Web UI port nên không thể truy cập bằng browser\n",
    "- Chỉ dùng cho Spark internal communication\n",
    "\n",
    "2. **Worker Port**:\n",
    "- Thiếu port mapping cho Worker UI\n",
    "- Sửa lại docker-compose như sau:\n",
    "\n",
    "```yaml:Main/Lambda/Batch_layer/docker-compose-batch.yml\n",
    "spark-worker:\n",
    "    image: bitnami/spark:latest\n",
    "    container_name: spark-worker\n",
    "    environment:\n",
    "      - SPARK_MODE=worker\n",
    "      - SPARK_MASTER_URL=spark://spark-master:7077\n",
    "      - SPARK_WORKER_MEMORY=1G\n",
    "      - SPARK_WORKER_CORES=1\n",
    "      - SPARK_RPC_MESSAGE_MAX_SIZE=2047\n",
    "      - SPARK_NETWORK_MAX_MESSAGE_SIZE=2047\n",
    "      # Thêm port cho Worker UI\n",
    "      - SPARK_WORKER_WEBUI_PORT=8081\n",
    "    ports:\n",
    "      - \"8081:8081\"  # Export Worker UI port\n",
    "    depends_on:\n",
    "      - spark-master\n",
    "    networks:\n",
    "      - batch_network\n",
    "```\n",
    "\n",
    "Sau khi sửa:\n",
    "1. Spark Master UI: `http://localhost:9090`\n",
    "2. Spark Worker UI: `http://localhost:8081`\n",
    "3. Port 7077: Chỉ dùng cho internal communication\n",
    "\n",
    "Kiểm tra:\n",
    "```bash\n",
    "# Restart services\n",
    "docker-compose -f docker-compose-batch.yml down\n",
    "docker-compose -f docker-compose-batch.yml up -d\n",
    "\n",
    "# Check logs\n",
    "docker logs spark-master\n",
    "docker logs spark-worker\n",
    "```\n",
    "\n",
    "Bây giờ bạn có thể:\n",
    "- Xem Master UI ở port 9090\n",
    "- Xem Worker UI ở port 8081\n",
    "- Port 7077 vẫn hoạt động cho internal communication\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "Check UI tại: \n",
    "- Master: `http://localhost:9090`\n",
    "- Worker: `http://localhost:8081`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3. Apach Kafka: \n",
    "\n",
    "Các thay đổi chính:\n",
    "Tăng MESSAGE_MAX_BYTES và các giới hạn liên quan lên 2GB\n",
    "Tăng buffer size cho socket\n",
    "Tăng fetch size cho partition\n",
    "\n",
    "Nếu vẫn gặp lỗi, có thể:\n",
    "- Giảm kích thước message gửi đi\n",
    "- Hoặc tăng thêm các giới hạn:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Memory Manager trong Kafka batch có các thành phần chính:\n",
    "\n",
    "1. **Heap Memory Management**:\n",
    "```yaml\n",
    "KAFKA_HEAP_OPTS: \"-Xmx4G -Xms4G\"\n",
    "```\n",
    "- `-Xmx4G`: Maximum heap size (tối đa 4GB)\n",
    "- `-Xms4G`: Initial heap size (khởi tạo 4GB)\n",
    "- Dùng cho: Java runtime, broker operations, cache\n",
    "\n",
    "2. **Network Memory**:\n",
    "```yaml\n",
    "KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 1024000\n",
    "KAFKA_SOCKET_SEND_BUFFER_BYTES: 1024000\n",
    "```\n",
    "- Buffer cho network operations\n",
    "- Xử lý incoming/outgoing requests\n",
    "\n",
    "3. **Message Size Management**:\n",
    "```yaml\n",
    "KAFKA_MESSAGE_MAX_BYTES: 2000000000        # Max message size\n",
    "KAFKA_MAX_REQUEST_SIZE: 2000000000         # Max request size\n",
    "KAFKA_MAX_PARTITION_FETCH_BYTES: 2000000000 # Max data per partition fetch\n",
    "```\n",
    "\n",
    "4. **Thread Management**:\n",
    "```yaml\n",
    "KAFKA_NUM_NETWORK_THREADS: 3    # Network threads\n",
    "KAFKA_NUM_IO_THREADS: 8         # I/O threads\n",
    "KAFKA_BACKGROUND_THREADS: 10    # Background processing\n",
    "```\n",
    "\n",
    "5. **Queue Management**:\n",
    "```yaml\n",
    "KAFKA_QUEUED_MAX_REQUESTS: 500  # Max requests in queue\n",
    "```\n",
    "\n",
    "Cách hoạt động:\n",
    "1. Network threads nhận requests\n",
    "2. Requests được đưa vào queue\n",
    "3. I/O threads xử lý từ queue\n",
    "4. Background threads xử lý maintenance tasks\n",
    "\n",
    "Khi gặp vấn đề memory:\n",
    "1. Tăng heap size\n",
    "2. Giảm message size\n",
    "3. Điều chỉnh số lượng threads\n",
    "4. Monitor memory usage\n",
    "\n",
    "\n",
    "\n",
    "### 4. Apach Zookeeper: \n",
    "- Vẫn còn lỗi \"Len error 1195725856\" với Zookeeper. \n",
    "- Có thể do các config không đúng. \n",
    "- Cần kiểm tra lại các config trong docker-compose-batch.yml và các file cấu hình khác. \n",
    "\n",
    "\n",
    "Vẫn còn lỗi \"Len error 1195725856\" với Zookeeper. Hãy thử điều chỉnh lại cấu hình Zookeeper như sau:\n",
    "\n",
    "```yaml:Main/Lambda/Batch_layer/docker-compose-batch.yml\n",
    "zookeeper:\n",
    "    image: confluentinc/cp-zookeeper:7.4.0\n",
    "    container_name: zookeeper-batch\n",
    "    ports:\n",
    "      - \"2182:2181\"\n",
    "    environment:\n",
    "      ZOOKEEPER_CLIENT_PORT: 2181\n",
    "      ZOOKEEPER_TICK_TIME: 2000\n",
    "      ZOOKEEPER_SYNC_LIMIT: 2\n",
    "      ZOOKEEPER_INIT_LIMIT: 5\n",
    "      \n",
    "      # Tăng buffer size và memory\n",
    "      JVMFLAGS: >-\n",
    "        -Djava.awt.headless=true\n",
    "        -Xmx2G -Xms2G\n",
    "        -Dzookeeper.maxClientCnxns=60\n",
    "        -Dzookeeper.jute.maxbuffer=8388608\n",
    "        -XX:+UseG1GC\n",
    "        -XX:MaxGCPauseMillis=200\n",
    "      \n",
    "      # Giới hạn kết nối và timeout\n",
    "      ZOOKEEPER_MAX_CLIENT_CNXNS: 60\n",
    "      ZOOKEEPER_MAX_SESSION_TIMEOUT: 60000\n",
    "      ZOOKEEPER_MIN_SESSION_TIMEOUT: 6000\n",
    "      \n",
    "      # Snapshot và cleanup\n",
    "      ZOOKEEPER_SNAP_RETAIN_COUNT: 5\n",
    "      ZOOKEEPER_PURGE_INTERVAL: 12\n",
    "      ZOOKEEPER_AUTOPURGE_PURGEINTERVAL: 12\n",
    "      ZOOKEEPER_AUTOPURGE_SNAPRETAINCOUNT: 5\n",
    "\n",
    "    volumes:\n",
    "      - zookeeper_data:/var/lib/zookeeper/data\n",
    "      - zookeeper_log:/var/lib/zookeeper/log\n",
    "    ulimits:\n",
    "      nofile:\n",
    "        soft: 65536\n",
    "        hard: 65536\n",
    "    networks:\n",
    "      - batch_network\n",
    "```\n",
    "\n",
    "Các thay đổi chính:\n",
    "\n",
    "1. Tăng memory và buffer:\n",
    "   - Heap size: 2GB\n",
    "   - jute.maxbuffer: 8MB\n",
    "   - Thêm G1GC collector\n",
    "\n",
    "2. Điều chỉnh timeout và connections:\n",
    "   - maxClientCnxns: 60 \n",
    "   - session timeout: 6s-60s\n",
    "\n",
    "3. Thêm cấu hình cleanup:\n",
    "   - Tự động purge mỗi 12 giờ\n",
    "   - Giữ 5 snapshots\n",
    "\n",
    "4. Thêm ulimits để tăng số file descriptors\n",
    "\n",
    "5. Thêm các tham số JVM tối ưu\n",
    "\n",
    "Sau khi sửa:\n",
    "\n",
    "```bash\n",
    "# Xóa volumes cũ\n",
    "docker-compose -f docker-compose-batch.yml down -v\n",
    "\n",
    "# Restart với cấu hình mới\n",
    "docker-compose -f docker-compose-batch.yml up -d\n",
    "\n",
    "# Kiểm tra logs\n",
    "docker logs zookeeper-batch\n",
    "```\n",
    "\n",
    "Nếu vẫn gặp lỗi:\n",
    "1. Tăng jute.maxbuffer lên 16MB hoặc 32MB\n",
    "2. Tăng heap size lên 4GB\n",
    "3. Giảm số lượng kết nối đồng thời\n",
    "4. Kiểm tra message size từ Kafka\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Trong Kafka, việc có 2 ports 9092 và 9093 là để phục vụ 2 mục đích khác nhau:\n",
    "\n",
    "1. **Port 9092 (PLAINTEXT://kafka:9092)**:\n",
    "- Dùng cho giao tiếp nội bộ giữa các containers trong Docker network\n",
    "- Các services trong cùng network như Spark, Airflow sẽ dùng port này\n",
    "- Địa chỉ `kafka:9092` chỉ có thể truy cập được từ bên trong Docker network\n",
    "\n",
    "2. **Port 9093 (PLAINTEXT_HOST://localhost:9093)**:\n",
    "- Dùng cho giao tiếp từ bên ngoài Docker (từ máy host)\n",
    "- Cho phép các ứng dụng chạy trên máy host kết nối đến Kafka\n",
    "- Địa chỉ `localhost:9093` có thể truy cập từ máy host\n",
    "\n",
    "Điều này được cấu hình trong:\n",
    "````yaml\n",
    "environment:\n",
    "  KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT\n",
    "  KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:9093\n",
    "````\n",
    "\n",
    "Ví dụ sử dụng:\n",
    "1. Từ container khác:\n",
    "````python\n",
    "# Dùng port 9092\n",
    "kafka_bootstrap_servers = 'kafka:9092'\n",
    "````\n",
    "\n",
    "2. Từ máy host:\n",
    "````python\n",
    "# Dùng port 9093 \n",
    "kafka_bootstrap_servers = 'localhost:9093'\n",
    "````\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để xem UI của Kafka, chúng ta cần thêm Kafka UI tool như Kafdrop hoặc AKHQ. Thêm service này vào docker-compose:\n",
    "\n",
    "```yaml\n",
    "# Thêm vào docker-compose-batch.yml\n",
    "  kafdrop:\n",
    "    image: obsidiandynamics/kafdrop:latest\n",
    "    container_name: kafdrop\n",
    "    depends_on:\n",
    "      - kafka\n",
    "    ports:\n",
    "      - \"9000:9000\"  # Port cho Web UI\n",
    "    environment:\n",
    "      KAFKA_BROKERCONNECT: kafka:9092\n",
    "      JVM_OPTS: \"-Xms32M -Xmx64M\"\n",
    "      SERVER_SERVLET_CONTEXTPATH: \"/\"\n",
    "    networks:\n",
    "      - batch_network\n",
    "```\n",
    "\n",
    "Sau đó:\n",
    "\n",
    "1. Restart services:\n",
    "```bash\n",
    "docker-compose -f docker-compose-batch.yml up -d\n",
    "```\n",
    "\n",
    "2. Truy cập Kafka UI:\n",
    "- Mở browser và truy cập: http://localhost:9000\n",
    "\n",
    "Qua UI này bạn có thể:\n",
    "- Xem danh sách topics\n",
    "- Xem/tạo partitions \n",
    "- Xem messages trong topics\n",
    "- Xem broker metrics\n",
    "- Quản lý consumer groups\n",
    "\n",
    "Port 9092/9093 chỉ là ports để kết nối tới Kafka broker, không phải để hiển thị UI.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- View Kafka on Confluence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "update Confluent Control Center into @docker-compose-batch.yml  (giữ nguyên các phần khác) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Lỗi này xảy ra do Kafka Streams đang cố gắng rebalance. Cần thêm một số cấu hình cho Control Center và Kafka:\n",
    "\n",
    "````yaml:Main/Lambda/Batch_layer/docker-compose-batch.yml\n",
    "  kafka:\n",
    "    # ... các config cũ giữ nguyên\n",
    "    environment:\n",
    "      # Thêm các config sau\n",
    "      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0\n",
    "      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1\n",
    "      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1\n",
    "      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1\n",
    "      KAFKA_AUTO_CREATE_TOPICS_ENABLE: \"true\"\n",
    "\n",
    "  control-center:\n",
    "    image: confluentinc/cp-enterprise-control-center:7.4.0\n",
    "    hostname: control-center\n",
    "    container_name: control-center\n",
    "    depends_on:\n",
    "      - kafka\n",
    "    ports:\n",
    "      - \"9021:9021\"\n",
    "    environment:\n",
    "      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'kafka:9092'\n",
    "      CONTROL_CENTER_REPLICATION_FACTOR: 1\n",
    "      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1\n",
    "      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1\n",
    "      CONFLUENT_METRICS_TOPIC_REPLICATION: 1\n",
    "      CONFLIENT_METRICS_ENABLE: 'false'\n",
    "      # Thêm các config sau\n",
    "      CONTROL_CENTER_STREAMS_NUM_STREAM_THREADS: 1\n",
    "      CONTROL_CENTER_COMMAND_TOPIC_REPLICATION: 1\n",
    "      CONTROL_CENTER_METRICS_TOPIC_REPLICATION: 1\n",
    "      CONTROL_CENTER_STREAMS_CONSUMER_REQUEST_TIMEOUT_MS: 960000\n",
    "      CONTROL_CENTER_STREAMS_PRODUCER_REQUEST_TIMEOUT_MS: 960000\n",
    "      PORT: 9021\n",
    "    networks:\n",
    "      - batch_network\n",
    "    healthcheck:\n",
    "      test: [ \"CMD\", \"curl\", \"-f\", \"http://localhost:9021/health\" ]\n",
    "      interval: 30s\n",
    "      timeout: 10s\n",
    "      retries: 5\n",
    "````\n",
    "\n",
    "Sau đó:\n",
    "\n",
    "````bash\n",
    "# Xóa volumes cũ\n",
    "docker volume rm $(docker volume ls -q)\n",
    "\n",
    "# Restart\n",
    "docker-compose -f docker-compose-batch.yml down\n",
    "docker-compose -f docker-compose-batch.yml up -d\n",
    "\n",
    "# Check logs\n",
    "docker logs control-center\n",
    "````\n",
    "\n",
    "Các thay đổi chính:\n",
    "1. Thêm cấu hình replication và transaction cho Kafka\n",
    "2. Thêm cấu hình streams và timeout cho Control Center\n",
    "3. Đặt replication factor = 1 vì chỉ có 1 broker\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
