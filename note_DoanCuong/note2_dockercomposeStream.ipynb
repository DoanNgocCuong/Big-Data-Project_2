{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chắc chắn rồi! Dưới đây là phần **\"How to Run\"** của dự án được giải thích chi tiết bằng tiếng Việt để bạn có thể dễ dàng thiết lập và chạy dự án của mình.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Cách Thức Chạy (How to Run)**\n",
    "\n",
    "Để thiết lập và chạy dự án cục bộ, hãy làm theo các bước dưới đây:\n",
    "\n",
    "### **Bước 1: Sao Chép Kho Lưu Trữ (Clone the Repository)**\n",
    "\n",
    "Trước tiên, bạn cần sao chép (clone) kho lưu trữ về máy tính của mình.\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/aymane-maghouti/Big-Data-Project\n",
    "```\n",
    "\n",
    "### **Bước 2: Chạy Tầng Stream (Stream Layer)**\n",
    "\n",
    "Tầng Stream chịu trách nhiệm xử lý dữ liệu thời gian thực. Dưới đây là các bước để khởi động tầng Stream:\n",
    "\n",
    "1. **Khởi động Apache Zookeeper**\n",
    "\n",
    "   Zookeeper là dịch vụ điều phối được sử dụng bởi Kafka để quản lý các broker và các dịch vụ liên quan.\n",
    "\n",
    "   ```bash\n",
    "   zookeeper-server-start.bat C:/kafka_2.13_2.6.0/config/zookeeper.properties\n",
    "   ```\n",
    "\n",
    "2. **Khởi động Kafka Server**\n",
    "\n",
    "   Kafka là hệ thống message broker dùng để xử lý và truyền tải dữ liệu thời gian thực.\n",
    "\n",
    "   ```bash\n",
    "   kafka-server-start.bat C:/kafka_2.13_2.6.0/config/server.properties\n",
    "   ```\n",
    "\n",
    "3. **Tạo Kafka Topic**\n",
    "\n",
    "   Topic là nơi dữ liệu sẽ được gửi và nhận trong Kafka.\n",
    "\n",
    "   ```bash\n",
    "   kafka-topics.bat --create --topic smartphoneTopic --bootstrap-server localhost:9092\n",
    "   ```\n",
    "\n",
    "4. **Chạy Kafka Producer**\n",
    "\n",
    "   Producer sẽ gửi dữ liệu vào Kafka Topic đã tạo.\n",
    "\n",
    "   ```bash\n",
    "   kafka-console-producer.bat --topic smartphoneTopic --bootstrap-server localhost:9092\n",
    "   ```\n",
    "\n",
    "   *Lưu ý:* Bạn có thể nhập dữ liệu trực tiếp vào dòng lệnh để gửi vào Kafka.\n",
    "\n",
    "5. **Chạy Kafka Consumer**\n",
    "\n",
    "   Consumer sẽ nhận dữ liệu từ Kafka Topic.\n",
    "\n",
    "   ```bash\n",
    "   kafka-console-consumer.bat --topic smartphoneTopic --from-beginning --bootstrap-server localhost:9092\n",
    "   ```\n",
    "\n",
    "6. **Khởi động HDFS và YARN**\n",
    "\n",
    "   HDFS là hệ thống lưu trữ phân tán, còn YARN quản lý tài nguyên cho các ứng dụng Hadoop.\n",
    "\n",
    "   ```bash\n",
    "   start-all\n",
    "   ```\n",
    "\n",
    "   *Lưu ý:* Lệnh này sẽ khởi động cả HDFS và YARN. Nếu gặp lỗi, bạn có thể khởi động riêng từng dịch vụ:\n",
    "\n",
    "   ```bash\n",
    "   start-dfs\n",
    "   start-yarn\n",
    "   ```\n",
    "\n",
    "7. **Khởi động HBase**\n",
    "\n",
    "   HBase là cơ sở dữ liệu NoSQL cung cấp khả năng truy xuất dữ liệu thời gian thực.\n",
    "\n",
    "   ```bash\n",
    "   start-hbase\n",
    "   ```\n",
    "\n",
    "8. **Chạy Thrift Server (Cho HBase)**\n",
    "\n",
    "   Thrift Server cho phép các ứng dụng không phải viết bằng Java tương tác với HBase.\n",
    "\n",
    "   ```bash\n",
    "   hbase thrift start\n",
    "   ```\n",
    "\n",
    "9. **Chạy Script `stream_pipeline.py`**\n",
    "\n",
    "   Sau khi đã khởi động tất cả các dịch vụ trên, bạn cần chạy script Python để xử lý dữ liệu stream.\n",
    "\n",
    "   ```bash\n",
    "   python stream_pipeline.py\n",
    "   ```\n",
    "\n",
    "10. **Chạy Ứng Dụng Spring Boot**\n",
    "\n",
    "    Mở dự án Spring Boot trong IDE (ví dụ: IntelliJ IDEA) và chạy ứng dụng. Bạn có thể truy cập ứng dụng web tại địa chỉ:\n",
    "\n",
    "    ```\n",
    "    http://localhost:8081/\n",
    "    ```\n",
    "\n",
    "    *Lưu ý:* Có phiên bản khác của ứng dụng web được phát triển bằng Flask. Bạn có thể xem video demo để biết thêm chi tiết.\n",
    "\n",
    "### **Bước 3: Chạy Tầng Batch (Batch Layer)**\n",
    "\n",
    "Tầng Batch xử lý dữ liệu hàng loạt và cung cấp các phân tích lịch sử.\n",
    "\n",
    "1. **Khởi động Apache Airflow**\n",
    "\n",
    "   Airflow được sử dụng để điều phối các workflow xử lý batch.\n",
    "\n",
    "   ```bash\n",
    "   docker-compose up -d\n",
    "   ```\n",
    "\n",
    "   *Lưu ý:* Đảm bảo bạn đang ở trong thư mục chứa tệp `docker-compose.all.yml` khi chạy lệnh này.\n",
    "\n",
    "2. **Truy cập Giao Diện Web của Apache Airflow**\n",
    "\n",
    "   Mở trình duyệt và truy cập:\n",
    "\n",
    "   ```\n",
    "   http://localhost:8080\n",
    "   ```\n",
    "\n",
    "   Tại đây, bạn có thể chạy DAG (Directed Acyclic Graph) để bắt đầu các workflow batch.\n",
    "\n",
    "3. **Khởi động Apache Spark**\n",
    "\n",
    "   Spark là framework xử lý dữ liệu lớn, được sử dụng để thực hiện các phép biến đổi dữ liệu.\n",
    "\n",
    "   ```bash\n",
    "   spark-shell\n",
    "   ```\n",
    "\n",
    "4. **Khởi động Apache Zookeeper và Kafka Server**\n",
    "\n",
    "   Nếu bạn chưa khởi động Zookeeper và Kafka trong bước Stream Layer, hãy thực hiện lại các lệnh sau:\n",
    "\n",
    "   ```bash\n",
    "   zookeeper-server-start.bat C:/kafka_2.13_2.6.0/config/zookeeper.properties\n",
    "   kafka-server-start.bat C:/kafka_2.13_2.6.0/config/server.properties\n",
    "   ```\n",
    "\n",
    "5. **Chạy Kafka Producer và Consumer**\n",
    "\n",
    "   Tương tự như bước Stream Layer, chạy producer và consumer để gửi và nhận dữ liệu.\n",
    "\n",
    "   ```bash\n",
    "   kafka-console-producer.bat --topic smartphoneTopic --bootstrap-server localhost:9092\n",
    "   kafka-console-consumer.bat --topic smartphoneTopic --from-beginning --bootstrap-server localhost:9092\n",
    "   ```\n",
    "\n",
    "6. **Khởi động HDFS và YARN**\n",
    "\n",
    "   ```bash\n",
    "   start-all\n",
    "   ```\n",
    "\n",
    "7. **Mở Tệp Power BI**\n",
    "\n",
    "   Sử dụng Power BI Desktop để mở tệp `dashboard.pbix` kèm theo dự án. Tệp này chứa bảng điều khiển (dashboard) để trực quan hóa dữ liệu.\n",
    "\n",
    "8. **Chạy Script `syc_with_Airflow.py`**\n",
    "\n",
    "   Sau khi đã khởi động tất cả các dịch vụ và mở bảng điều khiển, chạy script Python để đồng bộ hóa dữ liệu với Airflow.\n",
    "\n",
    "   ```bash\n",
    "   python syc_with_Airflow.py\n",
    "   ```\n",
    "\n",
    "### **Bước 4: Truy Cập Các Dashboard**\n",
    "\n",
    "Dự án sử dụng hai bảng điều khiển để trực quan hóa dữ liệu:\n",
    "\n",
    "1. **Dashboard Thời Gian Thực (Real-Time Dashboard - Ứng Dụng Spring Boot)**\n",
    "\n",
    "   - **Mô Tả:** Dashboard này được xây dựng bằng ứng dụng web Spring Boot, hiển thị giá dự đoán của smartphone theo thời gian thực.\n",
    "   - **Địa Chỉ Truy Cập:** `http://localhost:8081/`\n",
    "   - **Hình Ảnh Giao Diện:**\n",
    "     ![Spring Boot Web Application](images/spring_boot_web_app.png)\n",
    "\n",
    "2. **Dashboard Batch (Batch Dashboard - Power BI)**\n",
    "\n",
    "   - **Mô Tả:** Dashboard này sử dụng Power BI để khám phá dữ liệu tương tác, cung cấp cái nhìn sâu sắc về xu hướng giá smartphone trong quá khứ.\n",
    "   - **Địa Chỉ Truy Cập:** Mở tệp `dashboard.pbix` bằng Power BI Desktop.\n",
    "   - **Hình Ảnh Bảng Điều Khiển:**\n",
    "     ![Phone Dashboard](images/dashboard_phone.png)\n",
    "\n",
    "### **Bước 5: Lưu Ý Bổ Sung**\n",
    "\n",
    "- **Phiên Bản Ứng Dụng Web Khác:** Có phiên bản khác của ứng dụng web được phát triển bằng Flask micro-framework. Bạn có thể xem video demo để biết thêm chi tiết.\n",
    "\n",
    "---\n",
    "\n",
    "## **Tóm Tắt Các Bước Chạy Dự Án**\n",
    "\n",
    "1. **Clone kho lưu trữ về máy tính của bạn:**\n",
    "\n",
    "   ```bash\n",
    "   git clone https://github.com/aymane-maghouti/Big-Data-Project\n",
    "   ```\n",
    "\n",
    "2. **Khởi động tầng Stream:**\n",
    "\n",
    "   - Khởi động Zookeeper và Kafka.\n",
    "   - Tạo Kafka Topic.\n",
    "   - Chạy Kafka Producer và Consumer.\n",
    "   - Khởi động HDFS và YARN.\n",
    "   - Khởi động HBase và Thrift Server.\n",
    "   - Chạy script `stream_pipeline.py`.\n",
    "   - Khởi động ứng dụng Spring Boot và truy cập tại `http://localhost:8081/`.\n",
    "\n",
    "3. **Khởi động tầng Batch:**\n",
    "\n",
    "   - Khởi động Apache Airflow.\n",
    "   - Truy cập Airflow Web UI tại `http://localhost:8080` và chạy DAG.\n",
    "   - Khởi động Spark.\n",
    "   - Khởi động lại Zookeeper và Kafka nếu cần.\n",
    "   - Chạy Kafka Producer và Consumer.\n",
    "   - Khởi động HDFS và YARN.\n",
    "   - Mở bảng điều khiển Power BI.\n",
    "   - Chạy script `syc_with_Airflow.py`.\n",
    "\n",
    "4. **Truy cập các Dashboard:**\n",
    "\n",
    "   - **Real-Time Dashboard:** `http://localhost:8081/`\n",
    "   - **Batch Dashboard:** Mở `dashboard.pbix` bằng Power BI Desktop.\n",
    "\n",
    "---\n",
    "\n",
    "## **Lưu Ý Khi Chạy Dự Án**\n",
    "\n",
    "- **Yêu Cầu Phần Cứng:** Đảm bảo máy tính của bạn có đủ tài nguyên (CPU, RAM, bộ nhớ lưu trữ) để chạy đồng thời nhiều dịch vụ như Kafka, Zookeeper, HDFS, Spark, HBase, Airflow, và các ứng dụng web.\n",
    "  \n",
    "- **Cấu Hình Mạng:** Các dịch vụ cần được kết nối qua mạng nội bộ hoặc Docker Compose để đảm bảo giao tiếp hiệu quả giữa chúng.\n",
    "\n",
    "- **Quản Lý Tài Nguyên:** Sử dụng Docker Compose để quản lý và khởi động các dịch vụ một cách dễ dàng hơn.\n",
    "\n",
    "- **Kiểm Tra Log:** Nếu gặp sự cố, hãy kiểm tra log của từng dịch vụ để xác định nguyên nhân và khắc phục.\n",
    "\n",
    "---\n",
    "\n",
    "Hy vọng phần giải thích này sẽ giúp bạn thiết lập và chạy dự án một cách dễ dàng. Nếu bạn gặp bất kỳ vấn đề nào trong quá trình thiết lập hoặc chạy dự án, đừng ngần ngại hỏi thêm để được hỗ trợ!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
